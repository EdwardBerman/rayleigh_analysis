# Insights on Rayleigh over smoothing in GNNs and Implications for Dynamics Modeling

From [Edward Berman](https://ebrmn.space/) and [Luisa Li](https://www.luisali.com/). This project was done for [Robin Walters](https://www.robinwalters.com/) CS 7180 Special Topics Class on Geometric Structure in Deep Learning.

## Set Up Instructions

### General

1. This repository contains a submodule. To run this repository and access the submodules, run `git clone https://github.com/EdwardBerman/rayleigh_analysis.git` followed by `git submodule update --init --recursive` and `git submodule add https://github.com/mitkotak/fast_flops.git`. The repo will require non Pythonic dependencies, you will need to run `sudo apt install cmake gfortran`.
2. Install poetry and run `poetry install`
3. Install wandb via and login via `wandb login [api key]`

For plotting, you might need to download additional tex support locally for the LaTeX strings.

### Simulated Heat diffusion on graphs

1. To generate the heat diffusion data on a graph, do: `python3 -m toy_heat_diffusion.heat_data --n_sources 20 --minheat 1 --maxheat 1  --num_graphs 10000 --size_mean 10 --size_std 2 --time_max 10 --time_step 0.5`. Alternatively, the dataset we generated is available on Zenodo for download at [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17632910.svg)](https://doi.org/10.5281/zenodo.17632910)

2. To train a GCN on the heat diffusion data on graph, do `python3 -m toy_heat_diffusion.train --data_dir toy_heat_diffusion/data --start_time 0.0 --train_steps 5 --eval_steps 2 --model gcn --layers 12 --hidden 128 --epochs 200 --entity_name [wandb entity name] --project_name [wandb project name]`
3. To train the equivalent(ish) Separable Unitary GCN on the heat diffusion data on graph, do `python3 -m toy_heat_diffusion.train --data_dir toy_heat_diffusion/data --start_time 0.0 --train_steps 5 --eval_steps 2 --model separable_unitary --layers 12 --hidden 128 --epochs 200 --entity_name [wandb entity name] --project_name [wandb project name]`. 
4. For Lie Unitary GCN, simply change the `--model` flag to `lie_unitary` and add the flag `--act Identity`. The bias and skip connections will be set to false by default to keep the model unitary.
5. In addition to wandb, you can reproduce our plots by running `python3 -m toy_heat_diffusion.eval --data_dir_GCN [path to saved GCN npy files after training] --data_dir_UNI [path to uni npy files] --save_dir [optionally specify savedir, ../assets by default]`

Note, you can either set the seed with the `--set_seed` flag or aggregate results across multiple runs.


### PDEs on Meshes

1. The heat and wave datasets can be generated by running `python3 -m external.custom_hermes.generate_heat` and `python3 -m external.custom_hermes.generate_wave`
2. Alternatively, we generated sample heat and wave data with default settings (i.e. what is in the submodule) and placed it in `data`
3. You can run training via `python3 -m external.custom_hermes.train dataset=heat backbone=hermes`, this is also in `shell_scripts/mesh/mesh.sh`. The wandb paths are specified in `external/custom_hermes/conf/train.yaml`
4. For Hermes, EMAN, and GemCNN, we use the default Checkpoints supplied from the original Hermes paper for evaluation.
5. Models are evaluated using `shell_scripts/mesh/eval_mesh.sh` or `python3 -m external.custom_hermes.eval_rollout dataset=heat backbone=hermes model_save_path=model_checkpoints/[model pt file]`

### Long Range Graph Benchmark (Bonus)

1. The longe range graph benchmark can be downloaded by running `python3 -m data_preprocessing.long_range_graph_benchmark`
2. [Optional] Poke around with the datasets. Run `python3 -m data_preprocessing.homophily` to get the homophily distribution of graphs for the node level classification tasks. 
3. Run peptides with [insert here after done]

